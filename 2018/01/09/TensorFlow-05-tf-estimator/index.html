<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next2.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next2.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next2.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo2.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="TensorFlow," />










<meta name="description" content="tf.estimatorwhat’s tf.estimator?  TensorFlow’s high-level machine learning API (tf.estimator) makes it easy to configure, train, and evaluate a variety of machine learning models.">
<meta name="keywords" content="TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow_05: tf.estimator">
<meta property="og:url" content="http://www.enningxie.com/2018/01/09/TensorFlow-05-tf-estimator/index.html">
<meta property="og:site_name" content="Coolixz">
<meta property="og:description" content="tf.estimatorwhat’s tf.estimator?  TensorFlow’s high-level machine learning API (tf.estimator) makes it easy to configure, train, and evaluate a variety of machine learning models.">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-01-09T11:42:48.769Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow_05: tf.estimator">
<meta name="twitter:description" content="tf.estimatorwhat’s tf.estimator?  TensorFlow’s high-level machine learning API (tf.estimator) makes it easy to configure, train, and evaluate a variety of machine learning models.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '3ILT6D277E',
      apiKey: 'b4c6376d50c3288145cd43d1afc598b2',
      indexName: 'enning',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.enningxie.com/2018/01/09/TensorFlow-05-tf-estimator/"/>





  <title>TensorFlow_05: tf.estimator | Coolixz</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Coolixz</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Focus</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.enningxie.com/2018/01/09/TensorFlow-05-tf-estimator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="enningxie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/xz.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coolixz">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">TensorFlow_05: tf.estimator</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-09T19:42:48+08:00">
                2018-01-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TensorFlow/" itemprop="url" rel="index">
                    <span itemprop="name">TensorFlow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/09/TensorFlow-05-tf-estimator/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/01/09/TensorFlow-05-tf-estimator/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="tf-estimator"><a href="#tf-estimator" class="headerlink" title="tf.estimator"></a>tf.estimator</h3><p>what’s <code>tf.estimator</code>?</p>
<blockquote>
<p>TensorFlow’s high-level machine learning API (tf.estimator) makes it easy to configure, train, and evaluate a variety of machine learning models.</p>
</blockquote>
<a id="more"></a>
<p>Dataset: Iris data set.</p>
<blockquote>
<p>The Iris data set contains 150 rows of data, comprising 50 samples from each of three related Iris species: Iris setosa, Iris virginica, and Iris versicolor.</p>
</blockquote>
<p>the Iris data has been randomized and split into two separate CSVs:</p>
<ul>
<li><p>A training set of 120 samples(iris_training.csv)</p>
</li>
<li><p>A test set of 30 samples(iris_test.csv).</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># about tf.estimator</span></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"></div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">IRIS_TRAINING = <span class="string">'/home/enningxie/Documents/DataSets/iris/iris_training.csv'</span></div><div class="line">IRIS_TRAINING_URL = <span class="string">'http://download.tensorflow.org/data/iris_training.csv'</span></div><div class="line"></div><div class="line">IRIS_TEST = <span class="string">'/home/enningxie/Documents/DataSets/iris/iris_test.csv'</span></div><div class="line">IRIS_TEST_URL = <span class="string">'http://download.tensorflow.org/data/iris_test.csv'</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># download and store the dataset</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(pwd, url)</span>:</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(pwd):</div><div class="line">        print(<span class="string">"Downloading Training Set."</span>)</div><div class="line">        raw = urlopen(url).read()</div><div class="line">        <span class="keyword">with</span> open(IRIS_TRAINING, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">            f.write(raw)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        print(<span class="string">"existed."</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># load dataset</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(pwd)</span>:</span></div><div class="line">    data_set = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">        filename=pwd,</div><div class="line">        target_dtype=np.int,</div><div class="line">        features_dtype=np.float32</div><div class="line">    )</div><div class="line">    <span class="keyword">return</span> data_set</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># construct a dnn classifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">()</span>:</span></div><div class="line">    feature_columns = [tf.feature_column.numeric_column(<span class="string">"x"</span>, shape=[<span class="number">4</span>])]</div><div class="line">    <span class="comment"># build 3 layer dnn with 10, 20, 10 units respectively.</span></div><div class="line">    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,</div><div class="line">                                            hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">                                            n_classes=<span class="number">3</span>,</div><div class="line">                                            model_dir=<span class="string">"/home/enningxie/Documents/Models/iris_model"</span></div><div class="line">                                            )</div><div class="line">    <span class="keyword">return</span> classifier</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># train</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, input_data)</span>:</span></div><div class="line">    <span class="comment"># input</span></div><div class="line">    train_input = tf.estimator.inputs.numpy_input_fn(</div><div class="line">        x=&#123;<span class="string">"x"</span>: np.array(input_data.data)&#125;,</div><div class="line">        y=np.array(input_data.target),</div><div class="line">        num_epochs=<span class="keyword">None</span>,</div><div class="line">        shuffle=<span class="keyword">True</span></div><div class="line">    )</div><div class="line">    model.train(input_fn=train_input, steps=<span class="number">2000</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># test</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, input_data)</span>:</span></div><div class="line">    test_input = tf.estimator.inputs.numpy_input_fn(</div><div class="line">        x=&#123;<span class="string">"x"</span>: np.array(input_data.data)&#125;,</div><div class="line">        y=np.array(input_data.target),</div><div class="line">        num_epochs=<span class="number">1</span>,</div><div class="line">        shuffle=<span class="keyword">False</span></div><div class="line">    )</div><div class="line">    <span class="comment"># evaluate accuracy.</span></div><div class="line">    accuracy_score = model.evaluate(input_fn=test_input)[<span class="string">'accuracy'</span>]</div><div class="line">    print(<span class="string">"Test set accuracy: "</span>, accuracy_score)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># predict</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(model, input_data)</span>:</span></div><div class="line">    predict_input = tf.estimator.inputs.numpy_input_fn(</div><div class="line">        x=&#123;<span class="string">"x"</span>: input_data&#125;,</div><div class="line">        num_epochs=<span class="number">1</span>,</div><div class="line">        shuffle=<span class="keyword">False</span></div><div class="line">    )</div><div class="line">    predictions = list(model.predict(input_fn=predict_input))</div><div class="line">    predicted_classes = [p[<span class="string">'classes'</span>] <span class="keyword">for</span> p <span class="keyword">in</span> predictions]</div><div class="line">    print(<span class="string">"New samples, class predictions: "</span>, predicted_classes)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># main</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># download dataset</span></div><div class="line">    download(IRIS_TRAINING, IRIS_TRAINING_URL)</div><div class="line">    download(IRIS_TEST, IRIS_TEST_URL)</div><div class="line"></div><div class="line">    <span class="comment"># load dataset</span></div><div class="line">    training_set = load(IRIS_TRAINING)</div><div class="line">    test_set = load(IRIS_TEST)</div><div class="line"></div><div class="line">    classifier = model()</div><div class="line">    <span class="comment"># train</span></div><div class="line">    train(classifier, training_set)</div><div class="line">    <span class="comment"># test</span></div><div class="line">    test(classifier, test_set)</div><div class="line">    <span class="comment"># predict</span></div><div class="line">    new_samples = np.array(</div><div class="line">        [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>],</div><div class="line">         [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], dtype=np.float32)</div><div class="line">    predict(classifier, new_samples)</div><div class="line"></div><div class="line">    print(<span class="string">"end."</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<h4 id="Building-Input-Functions-with-tf-estimator"><a href="#Building-Input-Functions-with-tf-estimator" class="headerlink" title="Building Input Functions with tf.estimator"></a>Building Input Functions with <code>tf.estimator</code></h4><p>Introduces you to creating input functions in <code>tf.estimator</code>.</p>
<p>You will get an overview of how to construct an <code>input_fn</code> to preprocess and feed data into your models.</p>
<p>The <code>input_fn</code> is used to pass feature and target data to the <code>train</code>, <code>evaluate</code>, and <code>predict</code> methods of <code>Estimator</code>.</p>
<p>The user can do feature engineering or pre-processing inside the <code>input_fn</code>.</p>
<p>The following code illustrates the basic skeleton for an input function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_fn</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># Preprocess your data here ...</span></div><div class="line"></div><div class="line">    <span class="comment"># then return 1) a mapping of feature columns to Tensors with</span></div><div class="line">    <span class="comment"># the corresponding feature data, and 2) a Tensor containing labels</span></div><div class="line">    <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>Input functions must return the following two values containing the final feature and label data to be fed into your model.</p>
<p><code>feature_cols</code>:</p>
<p>A dict containing key/value pairs that map feature column names to Tensors (or SparseTensors) containing the corresponding feature data.</p>
<p><code>labels</code>:</p>
<p>A Tensor containing your label (target) values: the values your model aims to predict.</p>
<h4 id="Converting-Feature-Data-to-Tensors"><a href="#Converting-Feature-Data-to-Tensors" class="headerlink" title="Converting Feature Data to Tensors"></a>Converting Feature Data to Tensors</h4><p>if you feature/label data is a python array or stored in pandas dataframes or numpy arrays, you can use the following methods to construct <code>input_fn</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="comment"># numpy input_fn</span></div><div class="line">my_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">    x=&#123;<span class="string">"x"</span>: np.array(x_data)&#125;,</div><div class="line">    y=np.array(y_data),</div><div class="line">    ...</div><div class="line">)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="comment"># pandas input_fn</span></div><div class="line">my_input_fn = tf.estimator.inputs.pandas_input_fn(</div><div class="line">    x=pd.DataFrame(&#123;<span class="string">"x"</span>: x_data&#125;),</div><div class="line">    y=pd.Series(y_data),</div><div class="line">    ...</div><div class="line">)</div></pre></td></tr></table></figure>
<h4 id="Passing-input-fn-Data-to-Your-Model"><a href="#Passing-input-fn-Data-to-Your-Model" class="headerlink" title="Passing input_fn Data to Your Model"></a>Passing input_fn Data to Your Model</h4><p>To feed data to your model for training, you simply pass the input function you’ve created to your train operation as the value of the input_fn parameter, e.g.:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.train(input_fn=my_input_fn, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<h4 id="deal-with-pandas-data"><a href="#deal-with-pandas-data" class="headerlink" title="deal with pandas data"></a>deal with pandas data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># pandas input_fn</span></div><div class="line"><span class="comment"># DNNRegressor with custom input_fn for Housing dataset.</span></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"></div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">tf.logging.set_verbosity(tf.logging.INFO)</div><div class="line"></div><div class="line">COLUMNS = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>, <span class="string">"age"</span>,</div><div class="line">           <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>, <span class="string">"medv"</span>]</div><div class="line">FEATURES = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>,</div><div class="line">            <span class="string">"age"</span>, <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>]</div><div class="line">LABEL = <span class="string">"medv"</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># input_fn</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_input_fn</span><span class="params">(data_set, num_epochs=None, shuffle=True)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.estimator.inputs.pandas_input_fn(</div><div class="line">        x=pd.DataFrame(&#123;k: data_set[k].values <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;),</div><div class="line">        y=pd.Series(data_set[LABEL].values),</div><div class="line">        num_epochs=num_epochs,</div><div class="line">        shuffle=shuffle</div><div class="line">    )</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(unused_argv)</span>:</span></div><div class="line">    <span class="comment"># load datasets</span></div><div class="line">    training_set = pd.read_csv(<span class="string">"/home/enningxie/Documents/DataSets/boston/boston_train.csv"</span>, skipinitialspace=<span class="keyword">True</span>,</div><div class="line">                               skiprows=<span class="number">1</span>, names=COLUMNS)</div><div class="line">    test_set = pd.read_csv(<span class="string">"/home/enningxie/Documents/DataSets/boston/boston_test.csv"</span>, skipinitialspace=<span class="keyword">True</span>,</div><div class="line">                               skiprows=<span class="number">1</span>, names=COLUMNS)</div><div class="line">    prediction_set = pd.read_csv(<span class="string">"/home/enningxie/Documents/DataSets/boston/boston_predict.csv"</span>, skipinitialspace=<span class="keyword">True</span>,</div><div class="line">                               skiprows=<span class="number">1</span>, names=COLUMNS)</div><div class="line">    <span class="comment"># Feature cols</span></div><div class="line">    feature_cols = [tf.feature_column.numeric_column(k) <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</div><div class="line"></div><div class="line">    regressor = tf.estimator.DNNRegressor(</div><div class="line">        feature_columns=feature_cols,</div><div class="line">        hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</div><div class="line">        model_dir=<span class="string">"/home/enningxie/Documents/Models/boston/"</span></div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="comment"># train</span></div><div class="line">    regressor.train(input_fn=get_input_fn(training_set), steps=<span class="number">5000</span>)</div><div class="line"></div><div class="line">    <span class="comment"># evaluate</span></div><div class="line">    ev = regressor.evaluate(</div><div class="line">        input_fn=get_input_fn(test_set, num_epochs=<span class="number">1</span>, shuffle=<span class="keyword">False</span>)</div><div class="line">    )</div><div class="line">    loss_score = ev[<span class="string">"loss"</span>]</div><div class="line">    print(<span class="string">"Loss: &#123;0:f&#125;"</span>.format(loss_score))</div><div class="line"></div><div class="line">    <span class="comment"># prediction</span></div><div class="line">    y = regressor.predict(</div><div class="line">        input_fn=get_input_fn(prediction_set, num_epochs=<span class="number">1</span>, shuffle=<span class="keyword">False</span>)</div><div class="line">    )</div><div class="line">    predictions = list(p[<span class="string">"predictions"</span>] <span class="keyword">for</span> p <span class="keyword">in</span> itertools.islice(y, <span class="number">6</span>))</div><div class="line">    print(<span class="string">"Predictions: &#123;&#125;"</span>.format(str(predictions)))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    tf.app.run()</div></pre></td></tr></table></figure>
<h4 id="Advantages-of-Estimators"><a href="#Advantages-of-Estimators" class="headerlink" title="Advantages of Estimators"></a>Advantages of Estimators</h4><ul>
<li><p>You can run Estimators-based models on a local host or on a distributed multi-server environment without changing your model. Furthermore, you can run Estimators-based models on CPUs, GPUs, or TPUs without recoding your model.</p>
</li>
<li><p>Estimators simplify sharing implementations between model developers.</p>
</li>
<li><p>You can develop a state of the art model with high-level intuitive code, In short, it is generally much easier to create models with Estimators than with the low-level TensorFlow APIs.</p>
</li>
<li><p>Estimators are themselves built on tf.layers, which simplifies customization.</p>
</li>
<li><p>Estimators build the graph for you. In other words, you don’t have to build the graph.</p>
</li>
<li><p>Estimators provide a safe distributed training loop that controls how and when to: build the graph, initialize variables, start queues, handle exceptions, create checkpoint files and recover from failures, save summaries for TensorBoard.</p>
</li>
</ul>
<h4 id="Structure-of-a-pre-made-Estimators-program"><a href="#Structure-of-a-pre-made-Estimators-program" class="headerlink" title="Structure of a pre-made Estimators program"></a>Structure of a pre-made Estimators program</h4><ol>
<li><strong>Write one or more dataset importing functions.</strong> For example, you might create one function to import the training set and another function to import the test set. Each dataset importing function must return two objects:</li>
</ol>
<ul>
<li><p>a dictionary in which the keys are feature names and the values are Tensors (or SparseTensors) containing the corresponding feature data</p>
</li>
<li><p>a Tensor containing one or more labels</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(dataset)</span>:</span></div><div class="line">   ...  <span class="comment"># manipulate dataset, extracting feature names and the label</span></div><div class="line">   <span class="keyword">return</span> feature_dict, label</div></pre></td></tr></table></figure>
<ol>
<li><strong>Define the feature columns.</strong> Each tf.feature_column identifies a feature name, its type, and any input pre-processing. For example, the following snippet creates three feature columns that hold integer or floating-point data. The first two feature columns simply identify the feature’s name and type. The third feature column also specifies a lambda the program will invoke to scale the raw data:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Define three numeric feature columns.</span></div><div class="line">population = tf.feature_column.numeric_column(<span class="string">'population'</span>)</div><div class="line">crime_rate = tf.feature_column.numeric_column(<span class="string">'crime_rate'</span>)</div><div class="line">median_education = tf.feature_column.numeric_column(<span class="string">'median_education'</span>,</div><div class="line">                    normalizer_fn=<span class="string">'lambda x: x - global_education_mean'</span>)</div></pre></td></tr></table></figure>
<ol>
<li><strong>Instantiate the relevant pre-made Estimator.</strong> For example, here’s a sample instantiation of a pre-made Estimator named <code>LinearClassifier</code>:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Instantiate an estimator, passing the feature columns.</span></div><div class="line">estimator = tf.estimator.Estimator.LinearClassifier(</div><div class="line">    feature_columns=[population, crime_rate, median_education],</div><div class="line">    )</div></pre></td></tr></table></figure>
<ol>
<li><strong>Call a training, evaluation, or inference method.</strong> For example, all Estimators provide a train method, which trains a model.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># my_training_set is the function created in Step 1</span></div><div class="line">estimator.train(input_fn=my_training_set, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<h4 id="Benefits-of-pre-made-Estimators"><a href="#Benefits-of-pre-made-Estimators" class="headerlink" title="Benefits of pre-made Estimators"></a>Benefits of pre-made Estimators</h4><ul>
<li><p>Best practices for determining where different parts of the computational graph should run, implementing strategies on a single machine or on a cluster.</p>
</li>
<li><p>Best practices for event (summary) writing and universally useful summaries.</p>
</li>
</ul>
<h4 id="Recommended-workflow"><a href="#Recommended-workflow" class="headerlink" title="Recommended workflow"></a>Recommended workflow</h4><ol>
<li><p>Assuming a suitable pre-made Estimator exists, use it to build your first model and use its results to establish a baseline.</p>
</li>
<li><p>Build and test your overall pipeline, including the integrity and reliability of your data with this pre-made Estimator.</p>
</li>
<li><p>If suitable alternative pre-made Estimators are available, run experiments to determine which pre-made Estimator produces the best results.</p>
</li>
<li><p>Possibly, further improve your model by building your own custom Estimator.</p>
</li>
</ol>
<h4 id="Creating-Estimators-in-tf-estimator"><a href="#Creating-Estimators-in-tf-estimator" class="headerlink" title="Creating Estimators in tf.estimator"></a>Creating Estimators in <code>tf.estimator</code></h4><p>Let’s see how to create your own <code>Estimator</code> using the building blocks provided in <code>tf.estimator</code>.</p>
<p>you will learn:</p>
<ul>
<li><p>Instantiate an <code>Estimator</code></p>
</li>
<li><p>Construct a custom model function</p>
</li>
<li><p>Configure a neural network using <code>tf.feature_column</code> and <code>tf.layers</code></p>
</li>
<li><p>Choose an appropriate loss function from <code>tf.losses</code></p>
</li>
<li><p>Define a training op for your model</p>
</li>
<li><p>Generate and return predictions</p>
</li>
</ul>
<h4 id="Converting-Data-into-Tensors"><a href="#Converting-Data-into-Tensors" class="headerlink" title="Converting Data into Tensors"></a>Converting Data into Tensors</h4><p>Each continuous column in the train or test data will be converted into a Tensor, which in general is a good format to represent dense data. For categorical data, we must represent the data as a SparseTensor. This data format is good for representing sparse data.</p>
<h4 id="Base-Categorical-Feature-Columns"><a href="#Base-Categorical-Feature-Columns" class="headerlink" title="Base Categorical Feature Columns"></a>Base Categorical Feature Columns</h4><p>To define a feature column for a categorical feature, we can create a <code>CategoricalColumn</code> using the tf.feature_column API. If you know the set of all possible feature values of a column and there are only a few of them, you can use <code>categorical_column_with_vocabulary_list</code>. Each key in the list will get assigned an auto-incremental ID starting from 0. For example, for the <code>relationship</code> column we can assign the feature string “Husband” to an integer ID of 0 and “Not-in-family” to 1, etc., by doing:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">relationship = tf.feature_column.categorical_column_with_vocabulary_list(</div><div class="line">    <span class="string">'relationship'</span>, [</div><div class="line">        <span class="string">'Husband'</span>, <span class="string">'Not-in-family'</span>, <span class="string">'Wife'</span>, <span class="string">'Own-child'</span>, <span class="string">'Unmarried'</span>,</div><div class="line">        <span class="string">'Other-relative'</span>])</div></pre></td></tr></table></figure>
<p>What if we don’t know the set of possible values in advance? Not a problem. We can use <code>categorical_column_with_hash_bucket</code> instead:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">occupation = tf.feature_column.categorical_column_with_hash_bucket(</div><div class="line">    <span class="string">'occupation'</span>, hash_bucket_size=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<p>What will happen is that each possible value in the feature column occupation will be hashed to an integer ID as we encounter them in training.</p>
<p>If we want to learn the fine-grained correlation between income and each age group separately, we can leverage bucketization. Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive bins/buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into. So, we can define a <code>bucketized_column</code> over age as:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">age_buckets = tf.feature_column.bucketized_column(</div><div class="line">    age, boundaries=[<span class="number">18</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>, <span class="number">55</span>, <span class="number">60</span>, <span class="number">65</span>])</div></pre></td></tr></table></figure>
<p>where the <code>boundaries</code> is a list of bucket boundaries. In this case, there are 10 boundaries, resulting in 11 age group buckets (from age 17 and below, 18-24, 25-29, …, to 65 and over).</p>
<p>Using each base feature column separately may not be enough to explain the data. For example, the correlation between education and the label (earning &gt; 50,000 dollars) may be different for different occupations. Therefore, if we only learn a single model weight for education=”Bachelors” and education=”Masters”, we won’t be able to capture every single education-occupation combination (e.g. distinguishing between education=”Bachelors” AND occupation=”Exec-managerial” and education=”Bachelors” AND occupation=”Craft-repair”). To learn the differences between different feature combinations, we can add <code>crossed feature columns</code> to the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">education_x_occupation = tf.feature_column.crossed_column(</div><div class="line">    [<span class="string">'education'</span>, <span class="string">'occupation'</span>], hash_bucket_size=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<p>In the previous section we’ve seen several types of base and derived feature columns, including:</p>
<ul>
<li><p><code>CategoricalColumn</code></p>
</li>
<li><p><code>NumericColumn</code></p>
</li>
<li><p><code>BucketizedColumn</code></p>
</li>
<li><p><code>CrossedColumn</code></p>
</li>
</ul>
<p>All of these are subclasses of the abstract <code>FeatureColumn</code> class, and can be added to the <code>feature_columns</code> field of a model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">base_columns = [</div><div class="line">    education, marital_status, relationship, workclass, occupation,</div><div class="line">    age_buckets,</div><div class="line">]</div><div class="line">crossed_columns = [</div><div class="line">    tf.feature_column.crossed_column(</div><div class="line">        [<span class="string">'education'</span>, <span class="string">'occupation'</span>], hash_bucket_size=<span class="number">1000</span>),</div><div class="line">    tf.feature_column.crossed_column(</div><div class="line">        [age_buckets, <span class="string">'education'</span>, <span class="string">'occupation'</span>], hash_bucket_size=<span class="number">1000</span>),</div><div class="line">]</div><div class="line"></div><div class="line">model_dir = tempfile.mkdtemp()</div><div class="line">model = tf.estimator.LinearClassifier(</div><div class="line">    model_dir=model_dir, feature_columns=base_columns + crossed_columns)</div></pre></td></tr></table></figure>
<h4 id="Training-and-Evaluating-Our-Model"><a href="#Training-and-Evaluating-Our-Model" class="headerlink" title="Training and Evaluating Our Model"></a>Training and Evaluating Our Model</h4><p>After adding all the features to the model, now let’s look at how to actually train the model. Training a model is just a single command using the tf.estimator API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.train(input_fn=<span class="keyword">lambda</span>: input_fn(train_data, num_epochs, <span class="keyword">True</span>, batch_size))</div></pre></td></tr></table></figure>
<p>After the model is trained, we can evaluate how good our model is at predicting the labels of the holdout data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">results = model.evaluate(input_fn=<span class="keyword">lambda</span>: input_fn(</div><div class="line">    test_data, <span class="number">1</span>, <span class="keyword">False</span>, batch_size))</div><div class="line"><span class="keyword">for</span> key <span class="keyword">in</span> sorted(results):</div><div class="line">  print(<span class="string">'%s: %s'</span> % (key, results[key]))</div></pre></td></tr></table></figure>
<p>The first line of the final output should be something like <code>accuracy: 0.83557522</code>, which means the accuracy is 83.6%. Feel free to try more features and transformations and see if you can do even better!</p>
<h4 id="Adding-Regularization-to-Prevent-Overfitting"><a href="#Adding-Regularization-to-Prevent-Overfitting" class="headerlink" title="Adding Regularization to Prevent Overfitting"></a>Adding Regularization to Prevent Overfitting</h4><p>Regularization is a technique used to avoid overfitting. Overfitting happens when your model does well on the data it is trained on, but worse on test data that the model has not seen before, such as live traffic. Overfitting generally occurs when a model is excessively complex, such as having too many parameters relative to the number of observed training data. Regularization allows for you to control your model’s complexity and makes the model more generalizable to unseen data.</p>
<p>In the Linear Model library, you can add L1 and L2 regularizations to the model as:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">model = tf.estimator.LinearClassifier(</div><div class="line">    model_dir=model_dir, feature_columns=base_columns + crossed_columns,</div><div class="line">    optimizer=tf.train.FtrlOptimizer(</div><div class="line">        learning_rate=<span class="number">0.1</span>,</div><div class="line">        l1_regularization_strength=<span class="number">1.0</span>,</div><div class="line">        l2_regularization_strength=<span class="number">1.0</span>))</div></pre></td></tr></table></figure>
<p>One important difference between L1 and L2 regularization is that L1 regularization tends to make model weights stay at zero, creating sparser models, whereas L2 regularization also tries to make the model weights closer to zero but not necessarily zero. Therefore, if you increase the strength of L1 regularization, you will have a smaller model size because many of the model weights will be zero. This is often desirable when the feature space is very large but sparse, and when there are resource constraints that prevent you from serving a model that is too large.</p>
<p>In practice, you should try various combinations of L1, L2 regularization strengths and find the best parameters that best control overfitting and give you a desirable model size.</p>
<p>Model training is an optimization problem: The goal is to find a set of model weights (i.e. model parameters) to minimize a loss function defined over the training data, such as logistic loss for Logistic Regression models. The loss function measures the discrepancy between the ground-truth label and the model’s prediction. If the prediction is very close to the ground-truth label, the loss value will be low; if the prediction is very far from the label, then the loss value would be high.</p>
<h4 id="construct-your-own-estimator"><a href="#construct-your-own-estimator" class="headerlink" title="construct your own estimator"></a>construct your own estimator</h4><p>when you’re creating your own estimator from scratch, the constructor accepts just two high-level parameters for model configuration, <code>model_fn</code> and <code>params</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)</div></pre></td></tr></table></figure>
<ul>
<li><p><code>model_fn</code>: A function object that contains all the aforementioned logic to support training, evaluation, and prediction. You are responsible for implementing that functionality.</p>
</li>
<li><p><code>params</code>: An optional dict of hyperparameters (e.g., learning rate, dropout) that will be passed into the <code>model_fn</code>.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Set model params</span></div><div class="line">model_params = &#123;<span class="string">"learning_rate"</span>: LEARNING_RATE&#125;</div><div class="line"></div><div class="line"><span class="comment"># Instantiate Estimator</span></div><div class="line">nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)</div></pre></td></tr></table></figure>
<h4 id="Constructing-the-model-fn"><a href="#Constructing-the-model-fn" class="headerlink" title="Constructing the model_fn"></a>Constructing the <code>model_fn</code></h4><p>The basic skeleton for an <code>Estimator</code> API model function looks like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></div><div class="line">   <span class="comment"># Logic to do the following:</span></div><div class="line">   <span class="comment"># 1. Configure the model via TensorFlow operations</span></div><div class="line">   <span class="comment"># 2. Define the loss function for training/evaluation</span></div><div class="line">   <span class="comment"># 3. Define the training operation/optimizer</span></div><div class="line">   <span class="comment"># 4. Generate predictions</span></div><div class="line">   <span class="comment"># 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object</span></div><div class="line">   <span class="keyword">return</span> EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)</div></pre></td></tr></table></figure>
<p>The <code>model_fn</code> must accept three arguments:</p>
<ul>
<li><p><code>features</code>: A dict containing the features passed to the model via <code>input_fn</code>.</p>
</li>
<li><p><code>labels</code>: A <code>Tensor</code> containing the labels passed to the model via <code>input_fn</code>. Will be empty for <code>predict()</code> calls, as these are the values the model will infer.</p>
</li>
<li><p><code>mode</code>: One of the following <code>tf.estimator.ModeKeys</code> string values indicating the context in which the <code>model_fn</code> was invoked:</p>
</li>
<li><p><code>tf.estimator.ModeKeys.TRAIN</code> The <code>model_fn</code> was invoked in training mode, namely via a <code>train()</code> call.</p>
</li>
<li><p><code>tf.estimator.ModeKeys.EVAL</code>. The <code>model_fn</code> was invoked in evaluation mode, namely via an <code>evaluate()</code> call.</p>
</li>
<li><p><code>tf.estimator.ModeKeys.PREDICT</code>. The <code>model_fn</code> was invoked in predict mode, namely via a <code>predict()</code> call.</p>
</li>
</ul>
<p><code>model_fn</code> may also accept a <code>params</code> argument containing a dict of hyperparameters used for training</p>
<p>The body of the function performs the following tasks (described in detail in the sections that follow):</p>
<ul>
<li><p>Configuring the mode</p>
</li>
<li><p>Defining the loss function used to calculate how closely the model’s predictions match the target values.</p>
</li>
<li><p>Defining the training operation that specifies the <code>optimizer</code> algorithm to minimize the loss values calculated by the loss function.</p>
</li>
</ul>
<p>The <code>model_fn</code> must return a <code>tf.estimator.EstimatorSpec</code> object, which contains the following values:</p>
<ul>
<li><p><code>mode</code> (required). The mode in which the model was run. Typically, you will return the mode argument of the <code>model_fn</code> here.</p>
</li>
<li><p><code>predictions</code> (required in <code>PREDICT</code> mode). A dict that maps key names of your choice to <code>Tensors</code> containing the predictions from the model, e.g.:<br><code>python predictions = {&quot;results&quot;: tensor_of_predictions}</code><br>In <code>PREDICT</code> mode, the dict that you return in <code>EstimatorSpec</code> will then be returned by predict(), so you can construct it in the format in which you’d like to consume it.</p>
</li>
<li><p><code>loss</code> (required in EVAL and TRAIN mode). A Tensor containing a scalar loss value: the output of the model’s loss function calculated over all the input examples. This is used in TRAIN mode for error handling and logging, and is automatically included as a metric in EVAL mode.</p>
</li>
<li><p><code>train_op</code> (required only in <code>TRAIN</code> mode). An Op that runs one step of training.</p>
</li>
<li><p><code>eval_metric_ops</code> (optional). A dict of name/value pairs specifying the metrics that will be calculated when the model runs in <code>EVAL</code> mode. The name is a label of your choice for the metric, and the value is the result of your metric calculation. The <code>tf.metrics</code> module provides predefined functions for a variety of common metrics. The following <code>eval_metric_ops</code> contains an <code>&quot;accuracy&quot;</code> metric calculated using <code>tf.metrics.accuracy</code>:<br><code>python eval_metric_ops = { &quot;accuracy&quot;: tf.metrics.accuracy(labels, predictions) }</code><br>If you do not specify <code>eval_metric_ops</code>, only <code>loss</code> will be calculated during evaluation.</p>
</li>
</ul>
<h4 id="Configuring-a-neural-network-with-tf-feature-column-and-tf-layers"><a href="#Configuring-a-neural-network-with-tf-feature-column-and-tf-layers" class="headerlink" title="Configuring a neural network with tf.feature_column and tf.layers"></a>Configuring a neural network with <code>tf.feature_column</code> and <code>tf.layers</code></h4><p>Constructing a neural network entails creating and connecting the input layer, the hidden layers, and the output layer.</p>
<p>The input layer is a series of nodes (one for each feature in the model) that will accept the feature data that is passed to the <code>model_fn</code> in the features argument. If features contains an n-dimensional <code>Tensor</code> with all your feature data, then it can serve as the input layer. If features contains a dict of feature columns passed to the model via an input function, you can convert it to an input-layer Tensor with the <code>tf.feature_column.input_layer</code> function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">input_layer = tf.feature_column.input_layer(</div><div class="line">    features=features, feature_columns=[age, height, weight])</div></pre></td></tr></table></figure>
<p>As shown above, <code>input_layer()</code> takes two required arguments:</p>
<ul>
<li><p><code>features</code>. A mapping from string keys to the <code>Tensors</code> containing the corresponding feature data. This is exactly what is passed to the <code>model_fn</code> in the <code>features</code> argument.</p>
</li>
<li><p><code>feature_columns</code>. A list of all the <code>FeatureColumns</code> in the model—age, height, and weight in the above example.</p>
</li>
</ul>
<p>The input layer of the neural network then must be connected to one or more hidden layers via an <code>activation function</code> that performs a nonlinear transformation on the data from the previous layer. The last hidden layer is then connected to the output layer, the final layer in the model. <code>tf.layers</code> provides the <code>tf.layers.dense</code> function for constructing fully connected layers. The activation is controlled by the activation argument. Some options to pass to the activation argument are:</p>
<ul>
<li><p><code>tf.nn.relu</code>. The following code creates a layer of <code>units</code> nodes fully connected to the previous layer <code>input_layer</code> with a ReLU activation function (<code>tf.nn.relu</code>):<br><code>python hidden_layer = tf.layers.dense( inputs=input_layer, units=10, activation=tf.nn.relu)</code></p>
</li>
<li><p><code>tf.nn.relu6</code>. The following code creates a layer of <code>units</code> nodes fully connected to the previous layer <code>hidden_layer</code> with a ReLU 6 activation function (<code>tf.nn.relu6</code>):<br><code>python second_hidden_layer = tf.layers.dense( inputs=hidden_layer, units=20, activation=tf.nn.relu)</code></p>
</li>
<li><p><code>None</code>. The following code creates a layer of units nodes fully connected to the previous layer <code>second_hidden_layer</code> with no activation function, just a linear transformation:<br><code>python output_layer = tf.layers.dense( inputs=second_hidden_layer, units=3, activation=None)</code></p>
</li>
</ul>
<p>Other activation functions are possible, e.g.:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">output_layer = tf.layers.dense(inputs=second_hidden_layer,</div><div class="line">                               units=<span class="number">10</span>,</div><div class="line">                               activation_fn=tf.sigmoid)</div></pre></td></tr></table></figure>
<p>The above code creates the neural network layer <code>output_layer</code>, which is fully connected to <code>second_hidden_layer</code> with a sigmoid activation function (<code>tf.sigmoid</code>).</p>
<p>Putting it all together, the following code constructs a full neural network for the abalone predictor, and captures its predictions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></div><div class="line">  <span class="string">"""Model function for Estimator."""</span></div><div class="line"></div><div class="line">  <span class="comment"># Connect the first hidden layer to input layer</span></div><div class="line">  <span class="comment"># (features["x"]) with relu activation</span></div><div class="line">  first_hidden_layer = tf.layers.dense(features[<span class="string">"x"</span>], <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the second hidden layer to first hidden layer with relu</span></div><div class="line">  second_hidden_layer = tf.layers.dense(</div><div class="line">      first_hidden_layer, <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the output layer to second hidden layer (no activation fn)</span></div><div class="line">  output_layer = tf.layers.dense(second_hidden_layer, <span class="number">1</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Reshape output layer to 1-dim Tensor to return predictions</span></div><div class="line">  predictions = tf.reshape(output_layer, [<span class="number">-1</span>])</div><div class="line">  predictions_dict = &#123;<span class="string">"ages"</span>: predictions&#125;</div><div class="line">  ...</div></pre></td></tr></table></figure>
<p>Here, because you’ll be passing the Datasets using <code>numpy_input_fn</code> as shown below, features is a dict <code>{&quot;x&quot;: data_tensor}</code>, so <code>features[&quot;x&quot;]</code> is the input layer. The network contains two hidden layers, each with 10 nodes and a <code>ReLU</code> activation function. The output layer contains no activation function, and is tf.reshape to a one-dimensional tensor to capture the model’s predictions, which are stored in <code>predictions_dict</code>.</p>
<h4 id="Defining-loss-for-the-model"><a href="#Defining-loss-for-the-model" class="headerlink" title="Defining loss for the model"></a>Defining loss for the model</h4><p>The <code>EstimatorSpec</code> returned by the <code>model_fn</code> must contain <code>loss</code>: a <code>Tensor</code> representing the loss value, which quantifies how well the model’s predictions reflect the label values during training and evaluation runs. The <code>tf.losses</code> module provides convenience functions for calculating loss using a variety of metrics, including:</p>
<ul>
<li><p><code>absolute_difference</code>(labels, predictions). Calculates loss using the absolute-difference formula (also known as L1 loss).</p>
</li>
<li><p><code>log_loss</code>(labels, predictions). Calculates loss using the logistic loss forumula (typically used in logistic regression).</p>
</li>
<li><p><code>mean_squared_error</code>(labels, predictions). Calculates loss using the mean squared error (MSE; also known as L2 loss).</p>
</li>
</ul>
<p>The following example adds a definition for <code>loss</code> to the <code>model_fn</code> using <code>mean_squared_error()</code> (in bold):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></div><div class="line">  <span class="string">"""Model function for Estimator."""</span></div><div class="line"></div><div class="line">  <span class="comment"># Connect the first hidden layer to input layer</span></div><div class="line">  <span class="comment"># (features["x"]) with relu activation</span></div><div class="line">  first_hidden_layer = tf.layers.dense(features[<span class="string">"x"</span>], <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the second hidden layer to first hidden layer with relu</span></div><div class="line">  second_hidden_layer = tf.layers.dense(</div><div class="line">      first_hidden_layer, <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the output layer to second hidden layer (no activation fn)</span></div><div class="line">  output_layer = tf.layers.dense(second_hidden_layer, <span class="number">1</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Reshape output layer to 1-dim Tensor to return predictions</span></div><div class="line">  predictions = tf.reshape(output_layer, [<span class="number">-1</span>])</div><div class="line">  predictions_dict = &#123;<span class="string">"ages"</span>: predictions&#125;</div><div class="line"></div><div class="line">  <span class="comment"># Calculate loss using mean squared error</span></div><div class="line">  loss = tf.losses.mean_squared_error(labels, predictions)</div><div class="line">  ...</div></pre></td></tr></table></figure>
<p>Supplementary metrics for evaluation can be added to an <code>eval_metric_ops</code> dict. The following code defines an rmse metric, which calculates the root mean squared error for the model predictions. Note that the labels tensor is cast to a float64 type to match the data type of the predictions tensor, which will contain real values:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">eval_metric_ops = &#123;</div><div class="line">    <span class="string">"rmse"</span>: tf.metrics.root_mean_squared_error(</div><div class="line">        tf.cast(labels, tf.float64), predictions)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Defining-the-training-op-for-the-model"><a href="#Defining-the-training-op-for-the-model" class="headerlink" title="Defining the training op for the model"></a>Defining the training op for the model</h4><p>The training op defines the optimization algorithm TensorFlow will use when fitting the model to the training data. Typically when training, the goal is to minimize loss. A simple way to create the training op is to instantiate a <code>tf.train.Optimizer</code> subclass and call the minimize method.</p>
<p>The following code defines a training op for the model_fn using the loss value calculated in <code>Defining Loss for the Model</code>, the learning rate passed to the function in params, and the gradient descent optimizer. For <code>global_step</code>, the convenience function <code>tf.train.get_global_step</code> takes care of generating an integer variable:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">optimizer = tf.train.GradientDescentOptimizer(</div><div class="line">    learning_rate=params[<span class="string">"learning_rate"</span>])</div><div class="line">train_op = optimizer.minimize(</div><div class="line">    loss=loss, global_step=tf.train.get_global_step())</div></pre></td></tr></table></figure>
<h4 id="The-complete-model-fn"><a href="#The-complete-model-fn" class="headerlink" title="The complete model_fn"></a>The complete model_fn</h4><p>Here’s the final, complete <code>model_fn</code>. The following code configures the neural network; defines loss and the training op; and returns a <code>EstimatorSpec</code> object containing <code>mode</code>, <code>predictions_dict</code>, <code>loss</code>, and <code>train_op</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></div><div class="line">  <span class="string">"""Model function for Estimator."""</span></div><div class="line"></div><div class="line">  <span class="comment"># Connect the first hidden layer to input layer</span></div><div class="line">  <span class="comment"># (features["x"]) with relu activation</span></div><div class="line">  first_hidden_layer = tf.layers.dense(features[<span class="string">"x"</span>], <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the second hidden layer to first hidden layer with relu</span></div><div class="line">  second_hidden_layer = tf.layers.dense(</div><div class="line">      first_hidden_layer, <span class="number">10</span>, activation=tf.nn.relu)</div><div class="line"></div><div class="line">  <span class="comment"># Connect the output layer to second hidden layer (no activation fn)</span></div><div class="line">  output_layer = tf.layers.dense(second_hidden_layer, <span class="number">1</span>)</div><div class="line"></div><div class="line">  <span class="comment"># Reshape output layer to 1-dim Tensor to return predictions</span></div><div class="line">  predictions = tf.reshape(output_layer, [<span class="number">-1</span>])</div><div class="line"></div><div class="line">  <span class="comment"># Provide an estimator spec for `ModeKeys.PREDICT`.</span></div><div class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.PREDICT:</div><div class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(</div><div class="line">        mode=mode,</div><div class="line">        predictions=&#123;<span class="string">"ages"</span>: predictions&#125;)</div><div class="line"></div><div class="line">  <span class="comment"># Calculate loss using mean squared error</span></div><div class="line">  loss = tf.losses.mean_squared_error(labels, predictions)</div><div class="line"></div><div class="line">  <span class="comment"># Calculate root mean squared error as additional eval metric</span></div><div class="line">  eval_metric_ops = &#123;</div><div class="line">      <span class="string">"rmse"</span>: tf.metrics.root_mean_squared_error(</div><div class="line">          tf.cast(labels, tf.float64), predictions)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  optimizer = tf.train.GradientDescentOptimizer(</div><div class="line">      learning_rate=params[<span class="string">"learning_rate"</span>])</div><div class="line">  train_op = optimizer.minimize(</div><div class="line">      loss=loss, global_step=tf.train.get_global_step())</div><div class="line"></div><div class="line">  <span class="comment"># Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.</span></div><div class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(</div><div class="line">      mode=mode,</div><div class="line">      loss=loss,</div><div class="line">      train_op=train_op,</div><div class="line">      eval_metric_ops=eval_metric_ops)</div></pre></td></tr></table></figure>
<h4 id="Running-the-model"><a href="#Running-the-model" class="headerlink" title="Running the model"></a>Running the model</h4><p>You’ve instantiated an <code>Estimator</code> and defined its behavior in <code>model_fn</code>; all that’s left to do is <code>train</code>, <code>evaluate</code>, and make <code>predictions</code>.</p>
<p>Add the following code to the end of <code>main()</code> to fit the neural network to the training data and evaluate accuracy:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">    x=&#123;<span class="string">"x"</span>: np.array(training_set.data)&#125;,</div><div class="line">    y=np.array(training_set.target),</div><div class="line">    num_epochs=<span class="keyword">None</span>,</div><div class="line">    shuffle=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment"># Train</span></div><div class="line">nn.train(input_fn=train_input_fn, steps=<span class="number">5000</span>)</div><div class="line"></div><div class="line"><span class="comment"># Score accuracy</span></div><div class="line">test_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">    x=&#123;<span class="string">"x"</span>: np.array(test_set.data)&#125;,</div><div class="line">    y=np.array(test_set.target),</div><div class="line">    num_epochs=<span class="number">1</span>,</div><div class="line">    shuffle=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">ev = nn.evaluate(input_fn=test_input_fn)</div><div class="line">print(<span class="string">"Loss: %s"</span> % ev[<span class="string">"loss"</span>])</div><div class="line">print(<span class="string">"Root Mean Squared Error: %s"</span> % ev[<span class="string">"rmse"</span>])</div></pre></td></tr></table></figure>
<p>To predict ages for the <code>ABALONE_PREDICT</code> data set, add the following to <code>main()</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Print out predictions</span></div><div class="line">predict_input_fn = tf.estimator.inputs.numpy_input_fn(</div><div class="line">    x=&#123;<span class="string">"x"</span>: prediction_set.data&#125;,</div><div class="line">    num_epochs=<span class="number">1</span>,</div><div class="line">    shuffle=<span class="keyword">False</span>)</div><div class="line">predictions = nn.predict(input_fn=predict_input_fn)</div><div class="line"><span class="keyword">for</span> i, p <span class="keyword">in</span> enumerate(predictions):</div><div class="line">  print(<span class="string">"Prediction %s: %s"</span> % (i + <span class="number">1</span>, p[<span class="string">"ages"</span>]))</div></pre></td></tr></table></figure>
<p>Congrats! You’ve successfully built a tf.estimator <code>Estimator</code> from scratch.</p>
<hr>
<p>step by step:</p>
<p><a href="https://www.tensorflow.org/get_started/estimator" target="_blank" rel="external">step 1</a></p>
<p><a href="https://www.tensorflow.org/get_started/input_fn" target="_blank" rel="external">step 2</a></p>
<p><a href="https://www.tensorflow.org/programmers_guide/estimators" target="_blank" rel="external">step 3</a></p>
<p><a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">step 4</a></p>
<p><a href="https://www.tensorflow.org/extend/estimators" target="_blank" rel="external">step 5</a></p>
<hr>
<p>xz</p>
<p>:)</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/08/TensorFlow-04-DNN/" rel="next" title="TensorFlow_04: DNN">
                <i class="fa fa-chevron-left"></i> TensorFlow_04: DNN
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/xz.jpg"
                alt="enningxie" />
            
              <p class="site-author-name" itemprop="name">enningxie</p>
              <p class="site-description motion-element" itemprop="description">coder</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/enningxie" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:enningxie@163.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-estimator"><span class="nav-number">1.</span> <span class="nav-text">tf.estimator</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Building-Input-Functions-with-tf-estimator"><span class="nav-number">1.1.</span> <span class="nav-text">Building Input Functions with tf.estimator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Converting-Feature-Data-to-Tensors"><span class="nav-number">1.2.</span> <span class="nav-text">Converting Feature Data to Tensors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Passing-input-fn-Data-to-Your-Model"><span class="nav-number">1.3.</span> <span class="nav-text">Passing input_fn Data to Your Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deal-with-pandas-data"><span class="nav-number">1.4.</span> <span class="nav-text">deal with pandas data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Advantages-of-Estimators"><span class="nav-number">1.5.</span> <span class="nav-text">Advantages of Estimators</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Structure-of-a-pre-made-Estimators-program"><span class="nav-number">1.6.</span> <span class="nav-text">Structure of a pre-made Estimators program</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Benefits-of-pre-made-Estimators"><span class="nav-number">1.7.</span> <span class="nav-text">Benefits of pre-made Estimators</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Recommended-workflow"><span class="nav-number">1.8.</span> <span class="nav-text">Recommended workflow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Creating-Estimators-in-tf-estimator"><span class="nav-number">1.9.</span> <span class="nav-text">Creating Estimators in tf.estimator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Converting-Data-into-Tensors"><span class="nav-number">1.10.</span> <span class="nav-text">Converting Data into Tensors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Base-Categorical-Feature-Columns"><span class="nav-number">1.11.</span> <span class="nav-text">Base Categorical Feature Columns</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-and-Evaluating-Our-Model"><span class="nav-number">1.12.</span> <span class="nav-text">Training and Evaluating Our Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adding-Regularization-to-Prevent-Overfitting"><span class="nav-number">1.13.</span> <span class="nav-text">Adding Regularization to Prevent Overfitting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#construct-your-own-estimator"><span class="nav-number">1.14.</span> <span class="nav-text">construct your own estimator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constructing-the-model-fn"><span class="nav-number">1.15.</span> <span class="nav-text">Constructing the model_fn</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Configuring-a-neural-network-with-tf-feature-column-and-tf-layers"><span class="nav-number">1.16.</span> <span class="nav-text">Configuring a neural network with tf.feature_column and tf.layers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Defining-loss-for-the-model"><span class="nav-number">1.17.</span> <span class="nav-text">Defining loss for the model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Defining-the-training-op-for-the-model"><span class="nav-number">1.18.</span> <span class="nav-text">Defining the training op for the model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-complete-model-fn"><span class="nav-number">1.19.</span> <span class="nav-text">The complete model_fn</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Running-the-model"><span class="nav-number">1.20.</span> <span class="nav-text">Running the model</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">enningxie</span>

  
</div>

<!-- 
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>

-->




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://enningxie.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.enningxie.com/2018/01/09/TensorFlow-05-tf-estimator/';
          this.page.identifier = '2018/01/09/TensorFlow-05-tf-estimator/';
          this.page.title = 'TensorFlow_05: tf.estimator';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://enningxie.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  











<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>



  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.3"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
